{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d202ffb-7f2b-4814-8b96-51e813894890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T09:54:55.934138Z",
     "iopub.status.busy": "2024-11-20T09:54:55.932938Z",
     "iopub.status.idle": "2024-11-20T09:54:59.779498Z",
     "shell.execute_reply": "2024-11-20T09:54:59.778206Z",
     "shell.execute_reply.started": "2024-11-20T09:54:55.934061Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698c73ea-4440-4020-8051-424b674b259e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T09:54:59.780887Z",
     "iopub.status.busy": "2024-11-20T09:54:59.780535Z",
     "iopub.status.idle": "2024-11-20T09:55:00.935230Z",
     "shell.execute_reply": "2024-11-20T09:55:00.933805Z",
     "shell.execute_reply.started": "2024-11-20T09:54:59.780858Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'address-ner-ccks-2021' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "from modelscope.msdatasets import MsDataset\n",
    "# 方式一\n",
    "# ds =  MsDataset.load('iic/address-ner-ccks-2021')\n",
    "\n",
    "# 方式二（本文采用方式）\n",
    "! git clone https://www.modelscope.cn/datasets/iic/address-ner-ccks-2021.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2f19b3-672b-4395-a972-05f63d6fa98c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T10:07:12.775316Z",
     "iopub.status.busy": "2024-11-20T10:07:12.774308Z",
     "iopub.status.idle": "2024-11-20T10:07:12.805548Z",
     "shell.execute_reply": "2024-11-20T10:07:12.803472Z",
     "shell.execute_reply.started": "2024-11-20T10:07:12.775240Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['杭', '州', '五', '洲', '国', '际']\n",
      "['B-city', 'E-city', 'B-poi', 'I-poi', 'I-poi', 'E-poi']\n",
      "entities:  [{'word': '杭', 'type': 'city'}, {'word': '五洲国', 'type': 'poi'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_entities_from_bio(text, tags):\n",
    "    entities = []\n",
    "    entity_name = \"\"\n",
    "    flag = []\n",
    "    for char, tag in zip(text, tags):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if entity_name:\n",
    "                # 当前实体结束，添加到entities列表中\n",
    "                entities.append({\"word\": entity_name, \"type\": flag[0]})\n",
    "                entity_name = \"\"\n",
    "            flag = [tag[2:]]  # 获取实体类型\n",
    "            entity_name += char\n",
    "        elif tag.startswith(\"I-\") and entity_name:\n",
    "            # 继续当前实体\n",
    "            entity_name += char\n",
    "            flag.append(tag[2:])\n",
    "        else:\n",
    "            if entity_name:\n",
    "                # 当前实体结束，添加到entities列表中\n",
    "                entities.append({\"word\": entity_name, \"type\": flag[0]})\n",
    "                entity_name = \"\"\n",
    "                flag = []\n",
    "    if entity_name:\n",
    "        # 添加最后一个实体\n",
    "        entities.append({\"word\": entity_name, \"type\": flag[0]})\n",
    "    return entities\n",
    "\n",
    "\n",
    "def parse_bio_file(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "        data = fin.read()\n",
    "    example_list = data.split(\"\\n\\n\")\n",
    "    # print(example_list[0])\n",
    "    # print(\"--\")\n",
    "    # print(example_list[1])\n",
    "    # print(len(example_list))\n",
    "\n",
    "    for example in example_list:\n",
    "        word_tag_list = example.split(\"\\n\")\n",
    "        word_list, tag_list = [], []\n",
    "        for word_tag in word_tag_list:\n",
    "            word_tag_split = word_tag.split()\n",
    "            word_list.append(word_tag_split[0])\n",
    "            tag_list.append(word_tag_split[1])\n",
    "        print(word_list)\n",
    "        print(tag_list)\n",
    "        entities = extract_entities_from_bio(\"\".join(word_list), tag_list)\n",
    "        print(\"entities: \", entities)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parse_bio_file(\"address-ner-ccks-2021/dev.conll\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25715d28-4ed5-40fd-918b-ad021af008cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T10:33:11.348463Z",
     "iopub.status.busy": "2024-11-20T10:33:11.347233Z",
     "iopub.status.idle": "2024-11-20T10:33:11.479361Z",
     "shell.execute_reply": "2024-11-20T10:33:11.477890Z",
     "shell.execute_reply.started": "2024-11-20T10:33:11.348387Z"
    }
   },
   "outputs": [],
   "source": [
    "def bieo_to_text_and_entities(file_path):\n",
    "    results = []  # 用于存储每个样本的文本及实体\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current_text = []  # 当前样本的文本\n",
    "    current_entity = []  # 当前实体的内容\n",
    "    current_type = None\n",
    "    entities = []  # 当前样本的实体列表\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:  # 遇到空行，保存当前样本\n",
    "            if current_entity:  # 保存未结束的实体\n",
    "                entities.append({\"type\": current_type, \"text\": \"\".join(current_entity)})\n",
    "            if current_text:  # 保存当前样本\n",
    "                results.append({\"text\": \"\".join(current_text), \"entities\": entities})\n",
    "            # 重置状态\n",
    "            current_text = []\n",
    "            current_entity = []\n",
    "            current_type = None\n",
    "            entities = []\n",
    "            continue\n",
    "\n",
    "        token, tag = line.split()  # 假设每行格式为 \"单词 TAG\"\n",
    "        current_text.append(token)\n",
    "\n",
    "        if tag.startswith(\"B-\"):  # 新实体的开始\n",
    "            if current_entity:  # 保存未结束的实体\n",
    "                entities.append({\"type\": current_type, \"text\": \"\".join(current_entity)})\n",
    "            current_entity = [token]\n",
    "            current_type = tag[2:]\n",
    "        elif tag.startswith(\"I-\") and current_type == tag[2:]:  # 当前实体的中间部分\n",
    "            current_entity.append(token)\n",
    "        elif tag.startswith(\"E-\") and current_type == tag[2:]:  # 当前实体的结束\n",
    "            current_entity.append(token)\n",
    "            entities.append({\"type\": current_type, \"text\": \"\".join(current_entity)})\n",
    "            current_entity = []  # 重置实体\n",
    "            current_type = None\n",
    "        elif tag == \"O\":  # 非实体\n",
    "            if current_entity:  # 保存未结束的实体\n",
    "                entities.append({\"type\": current_type, \"text\": \"\".join(current_entity)})\n",
    "            current_entity = []\n",
    "            current_type = None\n",
    "\n",
    "    # 文件结束后处理最后一个样本\n",
    "    if current_text:\n",
    "        if current_entity:  # 保存未结束的实体\n",
    "            entities.append({\"type\": current_type, \"text\": \"\".join(current_entity)})\n",
    "        results.append({\"text\": \"\".join(current_text), \"entities\": entities})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 示例：假设有一个名为 \"bieo_data.txt\" 的 BIEO 文件\n",
    "# file_path = \"address-ner-ccks-2021/dev.conll\"\n",
    "# samples = bieo_to_text_and_entities(file_path)\n",
    "\n",
    "# # 打印结果\n",
    "# for sample in samples:\n",
    "#     print(f\"完整文本: {sample['text']}\")\n",
    "#     for entity in sample[\"entities\"]:\n",
    "#         print(f\"  实体类型: {entity['type']}, 实体文本: {entity['text']}\")\n",
    "#     break\n",
    "\n",
    "\n",
    "entity_type_list = [\"Province\", \"city\", \"district\", \"town\", \"road\", \"road_number\", \"poi\", \"house_number\", \"other\"]\n",
    "\n",
    "\n",
    "def parse_bie_file(file_path):\n",
    "\n",
    "    all_prompt_example_list = []\n",
    "\n",
    "    \n",
    "    samples = bieo_to_text_and_entities(file_path)\n",
    "    for sample in samples:\n",
    "        \n",
    "        text = sample[\"text\"]\n",
    "        example_input = text\n",
    "        entities = sample[\"entities\"]\n",
    "        entities = {entity[\"type\"]: entity[\"text\"] for entity in entities}\n",
    "        \n",
    "        example_output = \"\"\n",
    "        for entity_type in entity_type_list:\n",
    "            entity_text = entities.get(entity_type, None)\n",
    "            if not entity_text:\n",
    "                continue\n",
    "            example_output += entity_type + \"=\" + entity_text + \"\\n\"\n",
    "        one_example = {\"query\": example_input, \"response\": example_output}\n",
    "        all_prompt_example_list.append(one_example)\n",
    "    \n",
    "    return all_prompt_example_list  \n",
    "        \n",
    "all_prompt_example_list = parse_bie_file(\"address-ner-ccks-2021/dev.conll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1a4ec59-ce5f-4239-8c27-092de8501e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T10:33:12.505891Z",
     "iopub.status.busy": "2024-11-20T10:33:12.505213Z",
     "iopub.status.idle": "2024-11-20T10:33:12.514335Z",
     "shell.execute_reply": "2024-11-20T10:33:12.513094Z",
     "shell.execute_reply.started": "2024-11-20T10:33:12.505838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '杭州五洲国际', 'response': 'city=杭州\\npoi=五洲国际\\n'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prompt_example_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33e18bbb-3215-49b2-b04c-66667c4de72c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T11:03:03.426067Z",
     "iopub.status.busy": "2024-11-20T11:03:03.425313Z",
     "iopub.status.idle": "2024-11-20T11:03:03.587478Z",
     "shell.execute_reply": "2024-11-20T11:03:03.586613Z",
     "shell.execute_reply.started": "2024-11-20T11:03:03.425991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"\\n将地址解析为各个语义单元，字段顺序为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，并确保未识别到的字段返回空字符串。\\n输入地址：杭州五洲国际\", 'response': 'city=杭州\\npoi=五洲国际\\n'}\n",
      "1970\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "输入：浙江省杭州市余杭区五常街道文一西路969号淘宝城5号楼，放前台\n",
    "\n",
    "输出：Province=浙江省 city=杭州市 district=余杭区 town=五常街道 road=文一西路road_number=969号 poi=淘宝城 house_number=5号楼 other=，放前台\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "prompts = [\n",
    "    \"请解析以下地址文本，提取出如下字段，并按顺序返回：['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']。如果某字段在文本中不存在，请返回空字符串。\",\n",
    "    \"将地址拆分为以下要素：省、市、区、乡镇、路名、门牌号、兴趣点、楼栋号及其他信息，并按顺序输出。如果缺少某部分，使用空字符串填充。\",\n",
    "    \"请将地址文本解析为结构化字段，顺序为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，无对应字段时返回空。\",\n",
    "    \"根据地址内容，提取并返回省、市、区、乡镇等字段。输出顺序固定为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，无内容的字段置空。\",\n",
    "    \"请对地址文本进行要素解析，返回['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']格式的字段列表，缺失字段留空。\",\n",
    "    \"解析地址信息，将其分解为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，若某字段不存在，返回空字符串。\",\n",
    "    \"请从输入的地址文本中识别出以下字段：省、市、区、乡镇、路名、门牌号等，按['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序返回结果，缺失字段填空。\",\n",
    "    \"将地址解析为各个语义单元，字段顺序为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，并确保未识别到的字段返回空字符串。\",\n",
    "    \"请从地址文本中提取如下字段：省、市、区等。结果按['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序返回，缺失字段置空。\",\n",
    "    \"请对以下地址文本进行字段解析，按照['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']的顺序返回解析结果，无法找到的字段置空。\",\n",
    "    \"将输入地址分解为省、市、区、POI 等字段，按顺序返回 ['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']，缺失字段返回空字符串。\",\n",
    "    \"请对地址文本进行分解，并将其整理为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']的格式输出，未找到的部分用空字符串填充。\",\n",
    "    \"根据输入的地址，提取并返回省、市、区、POI 等字段，按['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序输出，缺失的内容用空字符串代替。\",\n",
    "    \"解析地址，输出各字段：['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']。如果某字段内容缺失，返回空值。\",\n",
    "    \"请提取地址中的关键信息，并按照['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序输出，缺失字段置空。\",\n",
    "    \"将输入的地址文本分解为语义明确的字段，并按照['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序返回。未找到对应内容时，字段留空。\",\n",
    "    \"解析以下地址，将其结构化为['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']的字段列表，缺失部分用空字符串表示。\",\n",
    "    \"请对输入的地址进行语义拆分，并按照['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']顺序返回结构化数据，无对应内容时留空。\",\n",
    "    \"从地址中提取省、市、区等字段，并按照['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']输出结果，缺少内容时返回空字符串。\",\n",
    "    \"请将地址解析为结构化字段，依次返回['Province', 'city', 'district', 'town', 'road', 'road_number', 'poi', 'house_number', 'other']的值，若字段缺失，返回空值。\"\n",
    "]\n",
    "\n",
    "\n",
    "def gen_prompt_example(file_bie_path):\n",
    "    \n",
    "    all_prompt_example_list = parse_bie_file(\"address-ner-ccks-2021/dev.conll\")\n",
    "\n",
    "    \n",
    "\n",
    "    def gen_one_prompt_example(prompt, example):\n",
    "        prompt_input = \"\"\n",
    "        prompt_input += prompt_input + \"\\n\" + prompt + \"\\n输入地址：\" + example[\"query\"]\n",
    "        prompt_response = example[\"response\"]\n",
    "\n",
    "        return {\"query\": prompt_input, \"response\": prompt_response}\n",
    "        \n",
    "    all_sft_prompt_data_list = []\n",
    "    for example in all_prompt_example_list:\n",
    "        sample_prompts = random.sample(prompts, 1)  # 此户可以根据单个样本选择多个 prompt\n",
    "        for prompt in sample_prompts:\n",
    "            all_sft_prompt_data_list.append(gen_one_prompt_example(prompt, example))\n",
    "\n",
    "    with open(\"ner_sft_data.jsonl\", \"w\", encoding=\"utf-8\") as fout:\n",
    "        for sft_example in all_sft_prompt_data_list:\n",
    "            fout.write(json.dumps(sft_example, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(all_sft_prompt_data_list[0])\n",
    "    print(len(all_sft_prompt_data_list))\n",
    "        \n",
    "gen_prompt_example(\"address-ner-ccks-2021/train.conll\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59edebe-b1e9-4328-8940-dc5869d4ba00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
