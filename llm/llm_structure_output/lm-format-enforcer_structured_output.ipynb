{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cf82fe-80b3-456f-b108-7bf8a3a5595e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:12:08.213607Z",
     "iopub.status.busy": "2024-11-22T09:12:08.212445Z",
     "iopub.status.idle": "2024-11-22T09:12:12.484258Z",
     "shell.execute_reply": "2024-11-22T09:12:12.482902Z",
     "shell.execute_reply.started": "2024-11-22T09:12:08.213533Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "使用lm-format-enforcer实现结构化信息抽取。\n",
    "支持： transformers, LangChain, LlamaIndex, llama.cpp, vLLM, Haystack, NVIDIA TensorRT-LLM, ExLlamaV2.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import pipeline\n",
    "\n",
    "from typing import Annotated, List\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ed78c8-eab4-4896-a6ac-39f782c8d9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:12:12.485891Z",
     "iopub.status.busy": "2024-11-22T09:12:12.485484Z",
     "iopub.status.idle": "2024-11-22T09:12:26.085353Z",
     "shell.execute_reply": "2024-11-22T09:12:26.084109Z",
     "shell.execute_reply.started": "2024-11-22T09:12:12.485861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f7e992e78c48508b46b348c6b0042d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"names\": [\"张三\", \"李四\"],\n",
      "\"citys\": [\"上海\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class NameLocation(BaseModel):\n",
    "\n",
    "    names: Annotated[List[str], Field(description=\"抽取所有的姓名\")]\n",
    "    citys: Annotated[List[str], Field(description=\"抽取所有的城市\")]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class AnswerFormat(BaseModel):\n",
    "#     first_name: str\n",
    "#     last_name: str\n",
    "#     year_of_birth: int\n",
    "#     num_seasons_in_nba: int\n",
    "\n",
    "# Create a transformers pipeline\n",
    "hf_pipeline = pipeline('text-generation', model='/root/autodl-tmp/modelscope_cache/hub/Qwen/Qwen2-7B-Instruct-AWQ', \n",
    "                       device_map='auto',max_length=512)\n",
    "prompt = f'输入文本：张三和李四都喜欢上海。\\n 待抽取的json schema: {NameLocation.schema_json()} :\\n'\n",
    "\n",
    "# Create a character level parser and build a transformers prefix function from it\n",
    "parser = JsonSchemaParser(NameLocation.schema())\n",
    "prefix_function = build_transformers_prefix_allowed_tokens_fn(hf_pipeline.tokenizer, parser)\n",
    "\n",
    "# Call the pipeline with the prefix function\n",
    "output_dict = hf_pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "\n",
    "# Extract the results\n",
    "result = output_dict[0]['generated_text'][len(prompt):]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5eb1bf-e23f-4279-b7b4-9c9c56ccb5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
