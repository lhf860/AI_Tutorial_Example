{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T09:09:29.367674Z",
     "iopub.status.busy": "2024-07-03T09:09:29.366838Z",
     "iopub.status.idle": "2024-07-03T09:09:33.711445Z",
     "shell.execute_reply": "2024-07-03T09:09:33.710064Z",
     "shell.execute_reply.started": "2024-07-03T09:09:29.367592Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "\n",
    "cache_dir = \"/root/autodl-tmp\"\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PrefixEncoder, PrefixTuningConfig\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T09:09:33.716952Z",
     "iopub.status.busy": "2024-07-03T09:09:33.716710Z",
     "iopub.status.idle": "2024-07-03T09:09:33.736477Z",
     "shell.execute_reply": "2024-07-03T09:09:33.735410Z",
     "shell.execute_reply.started": "2024-07-03T09:09:33.716924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': ['以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\\n\\n2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\\n\\n3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。'],\n",
       " 'input': [''],\n",
       " 'instruction': ['保持健康的三个提示。']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ds = Dataset.load_from_disk(\"./alpaca_data_zh\")\n",
    "ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T09:09:33.738459Z",
     "iopub.status.busy": "2024-07-03T09:09:33.738201Z",
     "iopub.status.idle": "2024-07-03T09:09:37.342632Z",
     "shell.execute_reply": "2024-07-03T09:09:37.341442Z",
     "shell.execute_reply.started": "2024-07-03T09:09:33.738431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44fbc8f42164c22ac925884f1a09da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d350cc03c47499eaa87e686d0f4f2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e30291a4c54bc0a2b0127c5a458ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BloomTokenizerFast(name_or_path='Langboat/bloom-1b4-zh', vocab_size=46145, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"Langboat/bloom-1b4-zh\", cache_dir=os.path.join(cache_dir, \"bloom-1b4-zh\"))\n",
    "\n",
    "tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T09:09:37.344205Z",
     "iopub.status.busy": "2024-07-03T09:09:37.343948Z",
     "iopub.status.idle": "2024-07-03T09:09:37.355876Z",
     "shell.execute_reply": "2024-07-03T09:09:37.354654Z",
     "shell.execute_reply.started": "2024-07-03T09:09:37.344177Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def process_func(example):\n",
    "#     input_ids, attention_mask, labels =[], [], []\n",
    "#     instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"].strip() , \"\\n\\nAssistant: \"]))\n",
    "#     response = tokenizer(example[\"output\"] + tokenizer.eos_token)\n",
    "#     input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "#     attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "#     labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "\n",
    "#     max_length = 256\n",
    "#     if len(input_ids) > max_length:\n",
    "#         input_ids = input_ids[:max_length]\n",
    "#         attention_mask = attention_mask[:max_length]\n",
    "#         labels = labels[: max_length]\n",
    "#     return {\"input_ids\": input_ids, \"attention_mask\":attention_mask, \"labels\": labels}\n",
    "\n",
    "\n",
    "def process_func(example):\n",
    "    MAX_LENGTH = 256\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    response = tokenizer(example[\"output\"] + tokenizer.eos_token)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:26.995203Z",
     "iopub.status.busy": "2024-06-25T03:21:26.994731Z",
     "iopub.status.idle": "2024-06-25T03:21:27.067076Z",
     "shell.execute_reply": "2024-06-25T03:21:27.065361Z",
     "shell.execute_reply.started": "2024-06-25T03:21:26.995161Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [26283,\n",
       "  29,\n",
       "  210,\n",
       "  7160,\n",
       "  28215,\n",
       "  9905,\n",
       "  15211,\n",
       "  672,\n",
       "  189,\n",
       "  4340,\n",
       "  17245,\n",
       "  29,\n",
       "  210,\n",
       "  5040,\n",
       "  584,\n",
       "  7160,\n",
       "  28215,\n",
       "  9905,\n",
       "  15211,\n",
       "  1038,\n",
       "  189,\n",
       "  189,\n",
       "  20,\n",
       "  17,\n",
       "  210,\n",
       "  7160,\n",
       "  9239,\n",
       "  3365,\n",
       "  420,\n",
       "  9487,\n",
       "  1965,\n",
       "  15342,\n",
       "  9239,\n",
       "  6053,\n",
       "  355,\n",
       "  1227,\n",
       "  32998,\n",
       "  554,\n",
       "  34487,\n",
       "  1326,\n",
       "  17632,\n",
       "  355,\n",
       "  975,\n",
       "  5189,\n",
       "  39177,\n",
       "  6455,\n",
       "  355,\n",
       "  12144,\n",
       "  17335,\n",
       "  8481,\n",
       "  355,\n",
       "  1437,\n",
       "  12785,\n",
       "  6698,\n",
       "  23294,\n",
       "  672,\n",
       "  189,\n",
       "  21,\n",
       "  17,\n",
       "  210,\n",
       "  22905,\n",
       "  15356,\n",
       "  420,\n",
       "  9487,\n",
       "  15597,\n",
       "  22985,\n",
       "  373,\n",
       "  19320,\n",
       "  554,\n",
       "  18524,\n",
       "  554,\n",
       "  1229,\n",
       "  6663,\n",
       "  1467,\n",
       "  642,\n",
       "  16422,\n",
       "  18235,\n",
       "  27624,\n",
       "  17520,\n",
       "  8732,\n",
       "  355,\n",
       "  8729,\n",
       "  1246,\n",
       "  7110,\n",
       "  554,\n",
       "  1246,\n",
       "  16422,\n",
       "  642,\n",
       "  15224,\n",
       "  11367,\n",
       "  355,\n",
       "  718,\n",
       "  7160,\n",
       "  28215,\n",
       "  15356,\n",
       "  12577,\n",
       "  672,\n",
       "  189,\n",
       "  22,\n",
       "  17,\n",
       "  210,\n",
       "  20027,\n",
       "  18399,\n",
       "  420,\n",
       "  20027,\n",
       "  1079,\n",
       "  15713,\n",
       "  6455,\n",
       "  21230,\n",
       "  355,\n",
       "  34810,\n",
       "  9487,\n",
       "  1688,\n",
       "  8637,\n",
       "  967,\n",
       "  3958,\n",
       "  210,\n",
       "  43738,\n",
       "  20027,\n",
       "  420,\n",
       "  15822,\n",
       "  20027,\n",
       "  12785,\n",
       "  17374,\n",
       "  12115,\n",
       "  355,\n",
       "  5189,\n",
       "  9239,\n",
       "  8113,\n",
       "  355,\n",
       "  1437,\n",
       "  5706,\n",
       "  4202,\n",
       "  19112,\n",
       "  16610,\n",
       "  1276,\n",
       "  420,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  5040,\n",
       "  584,\n",
       "  7160,\n",
       "  28215,\n",
       "  9905,\n",
       "  15211,\n",
       "  1038,\n",
       "  189,\n",
       "  189,\n",
       "  20,\n",
       "  17,\n",
       "  210,\n",
       "  7160,\n",
       "  9239,\n",
       "  3365,\n",
       "  420,\n",
       "  9487,\n",
       "  1965,\n",
       "  15342,\n",
       "  9239,\n",
       "  6053,\n",
       "  355,\n",
       "  1227,\n",
       "  32998,\n",
       "  554,\n",
       "  34487,\n",
       "  1326,\n",
       "  17632,\n",
       "  355,\n",
       "  975,\n",
       "  5189,\n",
       "  39177,\n",
       "  6455,\n",
       "  355,\n",
       "  12144,\n",
       "  17335,\n",
       "  8481,\n",
       "  355,\n",
       "  1437,\n",
       "  12785,\n",
       "  6698,\n",
       "  23294,\n",
       "  672,\n",
       "  189,\n",
       "  21,\n",
       "  17,\n",
       "  210,\n",
       "  22905,\n",
       "  15356,\n",
       "  420,\n",
       "  9487,\n",
       "  15597,\n",
       "  22985,\n",
       "  373,\n",
       "  19320,\n",
       "  554,\n",
       "  18524,\n",
       "  554,\n",
       "  1229,\n",
       "  6663,\n",
       "  1467,\n",
       "  642,\n",
       "  16422,\n",
       "  18235,\n",
       "  27624,\n",
       "  17520,\n",
       "  8732,\n",
       "  355,\n",
       "  8729,\n",
       "  1246,\n",
       "  7110,\n",
       "  554,\n",
       "  1246,\n",
       "  16422,\n",
       "  642,\n",
       "  15224,\n",
       "  11367,\n",
       "  355,\n",
       "  718,\n",
       "  7160,\n",
       "  28215,\n",
       "  15356,\n",
       "  12577,\n",
       "  672,\n",
       "  189,\n",
       "  22,\n",
       "  17,\n",
       "  210,\n",
       "  20027,\n",
       "  18399,\n",
       "  420,\n",
       "  20027,\n",
       "  1079,\n",
       "  15713,\n",
       "  6455,\n",
       "  21230,\n",
       "  355,\n",
       "  34810,\n",
       "  9487,\n",
       "  1688,\n",
       "  8637,\n",
       "  967,\n",
       "  3958,\n",
       "  210,\n",
       "  43738,\n",
       "  20027,\n",
       "  420,\n",
       "  15822,\n",
       "  20027,\n",
       "  12785,\n",
       "  17374,\n",
       "  12115,\n",
       "  355,\n",
       "  5189,\n",
       "  9239,\n",
       "  8113,\n",
       "  355,\n",
       "  1437,\n",
       "  5706,\n",
       "  4202,\n",
       "  19112,\n",
       "  16610,\n",
       "  1276,\n",
       "  420,\n",
       "  2]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "\n",
    "tokenized_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:27.069172Z",
     "iopub.status.busy": "2024-06-25T03:21:27.068795Z",
     "iopub.status.idle": "2024-06-25T03:21:27.906472Z",
     "shell.execute_reply": "2024-06-25T03:21:27.903806Z",
     "shell.execute_reply.started": "2024-06-25T03:21:27.069135Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 创建模型\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-1b4-zh\", low_cpu_mem_usage=True, cache_dir=os.path.join(cache_dir, \"bloom-1b4-zh\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:27.908566Z",
     "iopub.status.busy": "2024-06-25T03:21:27.908239Z",
     "iopub.status.idle": "2024-06-25T03:21:27.921516Z",
     "shell.execute_reply": "2024-06-25T03:21:27.919557Z",
     "shell.execute_reply.started": "2024-06-25T03:21:27.908535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrefixTuningConfig(peft_type=<PeftType.PREFIX_TUNING: 'PREFIX_TUNING'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=10, token_dim=None, num_transformer_submodules=None, num_attention_heads=None, num_layers=None, encoder_hidden_size=None, prefix_projection=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. 创建prefix tuning\n",
    "from peft import PrefixTuningConfig, PrefixEncoder, TaskType\n",
    "config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=10, prefix_projection=True)\n",
    "\n",
    "config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:27.922751Z",
     "iopub.status.busy": "2024-06-25T03:21:27.922476Z",
     "iopub.status.idle": "2024-06-25T03:21:30.498282Z",
     "shell.execute_reply": "2024-06-25T03:21:30.495550Z",
     "shell.execute_reply.started": "2024-06-25T03:21:27.922723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mget_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'PreTrainedModel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpeft_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'PeftConfig'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmixed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'PeftModel | PeftMixedModel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPeftModel\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPeftMixedModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Returns a Peft model object from a model and a config.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        model ([`transformers.PreTrainedModel`]):\u001b[0m\n",
       "\u001b[0;34m            Model to be wrapped.\u001b[0m\n",
       "\u001b[0;34m        peft_config ([`PeftConfig`]):\u001b[0m\n",
       "\u001b[0;34m            Configuration object containing the parameters of the Peft model.\u001b[0m\n",
       "\u001b[0;34m        adapter_name (`str`, `optional`, defaults to `\"default\"`):\u001b[0m\n",
       "\u001b[0;34m            The name of the adapter to be injected, if not provided, the default adapter name is used (\"default\").\u001b[0m\n",
       "\u001b[0;34m        mixed (`bool`, `optional`, defaults to `False`):\u001b[0m\n",
       "\u001b[0;34m            Whether to allow mixing different (compatible) adapter types.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"custom\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_name_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mmixed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mPeftMixedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prompt_learning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prompt_learning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpeft_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_prompt_learning_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.10/site-packages/peft/mapping.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 2. 创建peft model\n",
    "from peft import get_peft_model\n",
    "# peft_model = get_peft_model(model=model)\n",
    "get_peft_model??\n",
    "\n",
    "peft_model = get_peft_model(model=model, peft_config=config,\n",
    "                           adapter_name=\"default\",\n",
    "                           mixed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:30.501613Z",
     "iopub.status.busy": "2024-06-25T03:21:30.501181Z",
     "iopub.status.idle": "2024-06-25T03:21:30.516894Z",
     "shell.execute_reply": "2024-06-25T03:21:30.514163Z",
     "shell.execute_reply.started": "2024-06-25T03:21:30.501576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (default): PrefixEncoder(\n",
       "    (embedding): Embedding(10, 2048)\n",
       "    (transform): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2048, out_features=98304, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "peft_model.prompt_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:30.519381Z",
     "iopub.status.busy": "2024-06-25T03:21:30.518899Z",
     "iopub.status.idle": "2024-06-25T03:21:30.532664Z",
     "shell.execute_reply": "2024-06-25T03:21:30.530265Z",
     "shell.execute_reply.started": "2024-06-25T03:21:30.519335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 205,641,728 || all params: 1,508,753,408 || trainable%: 13.6299\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T03:21:30.534857Z",
     "iopub.status.busy": "2024-06-25T03:21:30.534537Z",
     "iopub.status.idle": "2024-06-25T03:50:20.426236Z",
     "shell.execute_reply": "2024-06-25T03:50:20.424139Z",
     "shell.execute_reply.started": "2024-06-25T03:21:30.534829Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='838' max='838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [838/838 28:43, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.300800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.242700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.194600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.175500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.102800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=838, training_loss=2.1862079966324326, metrics={'train_runtime': 1725.7987, 'train_samples_per_second': 31.125, 'train_steps_per_second': 0.486, 'total_flos': 5.865138293440512e+16, 'train_loss': 2.1862079966324326, 'epoch': 1.9964264443120905})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 创建训练参数\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "args = TrainingArguments(output_dir=\"/root/autodl-tmp/prefix_tuning_model\",\n",
    "                         per_device_train_batch_size=16,\n",
    "                         gradient_accumulation_steps=4,\n",
    "                         learning_rate=8e-5, \n",
    "                         logging_steps=10, save_total_limit=2, save_steps=50,\n",
    "                         num_train_epochs=2)\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(model=peft_model,args = args,\n",
    "                  data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "                  train_dataset=tokenized_ds)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T04:37:45.833945Z",
     "iopub.status.busy": "2024-06-25T04:37:45.833081Z",
     "iopub.status.idle": "2024-06-25T04:37:47.050678Z",
     "shell.execute_reply": "2024-06-25T04:37:47.049842Z",
     "shell.execute_reply.started": "2024-06-25T04:37:45.833866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 考试有哪些技巧？\\n\\nAssistant: 考试有很多技巧，其中最关键的技巧之一是保持良好的心态。保持良好的心态不仅有助于提高考试成绩，而且有助于保持积极的心态，避免紧张和焦虑。此外，考试技巧还包括合理安排时间，合理分配精力，保持良好的作息习惯，以及合理饮食和锻炼身体。此外，考试技巧还包括保持良好的学习习惯，如按时完成作业，认真听课，及时复习等。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ipt = tokenizer(\"Human: {}\\n{}\".format(\"考试有哪些技巧？\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "tokenizer.decode(peft_model.generate(**ipt, max_length=128, do_sample=False)[0], skip_special_tokens=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
