{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e938af1-5f1a-460e-8607-02e6a996d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf9c1c-77ce-4de6-9da2-236bdae67c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "# 自定义的OpenAI LLM类\n",
    "class CustomOpenAIClientLLM(LLM):\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"EMPTY\", model=\"Qwen/Qwen2-7B-Instruct-AWQ\",\n",
    "                    temperature=0.01)\n",
    "    \n",
    "    # def __init__(self, model_name: str = \"Qwen/Qwen2-7B-Instruct-AWQ\", openai_api_key: str=\"EMPTY\", temperature: float = 0.01):\n",
    "        \n",
    "    #     # self.openai_api_key = openai_api_key\n",
    "    #     # self.temperature = temperature\n",
    "    #     # \"Qwen/Qwen2-7B-Instruct-AWQ\"\n",
    "    #     # openai_api_key = \"EMPTY\"\n",
    "    #     openai_api_base = \"http://localhost:8000/v1\"  # 默认是8000端口\n",
    "    #     self.model_name = model_name\n",
    "        \n",
    "    #     self.client = OpenAI(api_key=openai_api_key, base_url=openai_api_base, model=self.model_name)\n",
    "        \n",
    "        \n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_openai_client_llm\"\n",
    "\n",
    "    # 重写生成方法，使其通过OpenAI接口调用VLLM模型\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        try:\n",
    "            # 调用OpenAI接口\n",
    "            # response = openai.Completion.create(\n",
    "            #     model=self.model_name,\n",
    "            #     prompt=prompt,\n",
    "            #     temperature=self.temperature,\n",
    "            #     max_tokens=5256,\n",
    "            #     stop=stop\n",
    "            # )\n",
    "\n",
    "            response = self.llm.invoke(prompt)\n",
    "            print(response)\n",
    "                    \n",
    "            # 提取模型生成的文本\n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"OpenAI API调用失败: {e}\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为实际的模型名称和API key\n",
    "    llm = CustomOpenAIClientLLM()\n",
    "\n",
    "    # 测试调用\n",
    "    prompt = \"解释一下量子计算的基本原理.\"\n",
    "    result = llm(prompt)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0fa67db-c9aa-4334-b96b-f836ccb1bbc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T08:42:52.194647Z",
     "iopub.status.busy": "2024-10-16T08:42:52.193828Z",
     "iopub.status.idle": "2024-10-16T08:42:54.549099Z",
     "shell.execute_reply": "2024-10-16T08:42:54.547082Z",
     "shell.execute_reply.started": "2024-10-16T08:42:52.194562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "参考：https://python.langchain.com/docs/integrations/chat/openai/\n",
    "\"\"\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "cc = ChatOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"EMPTY\", model=\"Qwen/Qwen2-7B-Instruct-AWQ\")\n",
    "\n",
    "res = cc.invoke(\"解释一下量子计算机和人工智能的区别。\")\n",
    "       \n",
    "print(type(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee28e870-9c85-42cb-ac7f-8c10d33a1f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T08:33:35.276347Z",
     "iopub.status.busy": "2024-10-16T08:33:35.275871Z",
     "iopub.status.idle": "2024-10-16T08:33:35.285964Z",
     "shell.execute_reply": "2024-10-16T08:33:35.285000Z",
     "shell.execute_reply.started": "2024-10-16T08:33:35.276313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_openai.chat_models.base.ChatOpenAI"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fad6795-4cd1-43e5-85ec-501f994270c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T13:47:51.229372Z",
     "iopub.status.busy": "2024-10-16T13:47:51.228697Z",
     "iopub.status.idle": "2024-10-16T13:47:51.587766Z",
     "shell.execute_reply": "2024-10-16T13:47:51.586092Z",
     "shell.execute_reply.started": "2024-10-16T13:47:51.229322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='当前（2021年）美国总统是乔·拜登（Joe Biden）。请注意，美国总统可能会随着选举结果的更新而变化。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 27, 'total_tokens': 57, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2-7B-Instruct-AWQ', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5f95d13a-d558-47b4-9180-ddf9d1d1789a-0' usage_metadata={'input_tokens': 27, 'output_tokens': 30, 'total_tokens': 57}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "my_template = PromptTemplate.from_template(template=\"回答用户的问题。\\n\\nquery:{query}\")\n",
    "\n",
    "chain = my_template | cc\n",
    "\n",
    "\n",
    "print(chain.invoke({\"query\": \"美国总统是谁\"}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da93972-33d1-4dc2-a0b9-ad9cb3b096b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "state\n",
    "\"\"\"\n",
    "from typing import TypedDict, Optional, Annotated,List\n",
    "\n",
    "\n",
    "class YanFaState(TypedDict):\n",
    "    \n",
    "    query: str\n",
    "    relenvant_docs: Annotated[List[str]]\n",
    "    relevant_score: Annotated[List[float]]\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
